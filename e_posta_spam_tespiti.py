# -*- coding: utf-8 -*-
"""e_posta_spam_tespiti

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UDv_me6cw9dowdHlysJMS78EBMelX_js
"""

# Gerekli kütüphanelerin yüklenmesi
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.datasets import fetch_20newsgroups

# 1. Veri Yükleme ve Etiketleme
# Sadece iki kategori seçerek (örneğin rec.autos ve sci.crypt) sınıflandırma yapacağız
categories = ['rec.autos', 'sci.crypt']
newsgroups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))
X = newsgroups.data
y = [1 if target == 1 else 0 for target in newsgroups.target]  # sci.crypt -> 1 (spam), rec.autos -> 0 (ham)

# 2. Veri Setini Eğitim ve Test Olarak Bölme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF vektörizasyonu
vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 3. Model Eğitimi ve Testi

# Naive Bayes Modeli
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
nb_predictions = nb_model.predict(X_test_tfidf)

# SVM Modeli
svm_model = SVC(kernel='linear')
svm_model.fit(X_train_tfidf, y_train)
svm_predictions = svm_model.predict(X_test_tfidf)

# KNN Modeli
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_tfidf, y_train)
knn_predictions = knn_model.predict(X_test_tfidf)

# 4. Model Değerlendirmesi

# Naive Bayes Performansı
print("Naive Bayes Modeli")
print("Doğruluk:", accuracy_score(y_test, nb_predictions))
print(classification_report(y_test, nb_predictions))

# SVM Performansı
print("\nSVM Modeli")
print("Doğruluk:", accuracy_score(y_test, svm_predictions))
print(classification_report(y_test, svm_predictions))

# KNN Performansı
print("\nKNN Modeli")
print("Doğruluk:", accuracy_score(y_test, knn_predictions))
print(classification_report(y_test, knn_predictions))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Karışıklık Matrisini Çizdirme Fonksiyonu
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
    plt.xlabel("Tahmin")
    plt.ylabel("Gerçek")
    plt.title(title)
    plt.show()

# Naive Bayes Karışıklık Matrisi
plot_confusion_matrix(y_test, nb_predictions, "Naive Bayes Karışıklık Matrisi")

# SVM Karışıklık Matrisi
plot_confusion_matrix(y_test, svm_predictions, "SVM Karışıklık Matrisi")

# KNN Karışıklık Matrisi
plot_confusion_matrix(y_test, knn_predictions, "KNN Karışıklık Matrisi")

from sklearn.model_selection import GridSearchCV

# SVM için hiperparametre ayarı
param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)
grid.fit(X_train_tfidf, y_train)

# En iyi parametreler
print("En iyi SVM parametreleri:", grid.best_params_)

# En iyi SVM modeli ile tahmin yapma
svm_best_predictions = grid.predict(X_test_tfidf)
print("Grid Search ile En iyi SVM Modeli Doğruluk:", accuracy_score(y_test, svm_best_predictions))

import pandas as pd

# Sonuçları karşılaştırma
results = {
    "Model": ["Naive Bayes", "SVM", "KNN"],
    "Doğruluk": [
        accuracy_score(y_test, nb_predictions),
        accuracy_score(y_test, svm_predictions),
        accuracy_score(y_test, knn_predictions)
    ]
}

# DataFrame oluşturma ve gösterme
results_df = pd.DataFrame(results)
print(results_df)

from sklearn.metrics import roc_curve, auc

# Naive Bayes için ROC Eğrisi
nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_model.predict_proba(X_test_tfidf)[:,1])
nb_auc = auc(nb_fpr, nb_tpr)

# SVM için ROC Eğrisi (SVC için `decision_function` ile)
svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_model.decision_function(X_test_tfidf))
svm_auc = auc(svm_fpr, svm_tpr)

# KNN için ROC Eğrisi (KNN probabilite skorlarıyla)
knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_model.predict_proba(X_test_tfidf)[:,1])
knn_auc = auc(knn_fpr, knn_tpr)

# ROC Eğrisi Çizme
plt.figure()
plt.plot(nb_fpr, nb_tpr, label=f'Naive Bayes (AUC = {nb_auc:.2f})')
plt.plot(svm_fpr, svm_tpr, label=f'SVM (AUC = {svm_auc:.2f})')
plt.plot(knn_fpr, knn_tpr, label=f'KNN (AUC = {knn_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Eğrisi")
plt.legend()
plt.show()

# Naive Bayes yanlış sınıflandırmalar
misclassified_nb = [(text, true, pred) for text, true, pred in zip(X_test, y_test, nb_predictions) if true != pred]
print("Naive Bayes Hatalı Sınıflandırmalar:")
for i, (text, true, pred) in enumerate(misclassified_nb[:5]):  # İlk 5 hatalı örneği göster
    print(f"\nOrijinal: {true}, Tahmin: {pred}")
    print(text[:200], "...")  # Metnin ilk 200 karakterini yazdır

import joblib

# Modelleri kaydetme
joblib.dump(nb_model, 'naive_bayes_model.pkl')
joblib.dump(svm_model, 'svm_model.pkl')
joblib.dump(knn_model, 'knn_model.pkl')

# Modeli tekrar yüklemek için
# loaded_model = joblib.load('naive_bayes_model.pkl')
# loaded_predictions = loaded_model.predict(X_test_tfidf)